{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c1990d",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ace9afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import cloudpickle\n",
    "import ray\n",
    "from datetime import datetime\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "from typing import Dict, Callable, Union, Tuple, List, Optional, Iterable\n",
    "from datetime import timedelta as td\n",
    "from scipy import stats\n",
    "import time\n",
    "def load(path: str):\n",
    "    with open(path, mode='rb') as f:\n",
    "        return cloudpickle.load(f)\n",
    "def dump(obj, path: str):\n",
    "    with open(path, mode='wb') as f:\n",
    "        cloudpickle.dump(obj, f)\n",
    "def log(msg: any):\n",
    "    print('[{}] {}'.format(datetime.now().strftime('%y-%m-%d %H:%M:%S'), msg))\n",
    "@contextmanager\n",
    "def log_t(msg: any):\n",
    "    try:\n",
    "        s = time.time()\n",
    "        yield None\n",
    "    finally:\n",
    "        elasped_time = time.time() - s\n",
    "        log(f'({elasped_time:.2f}s) {msg}')\n",
    "def summary(x):\n",
    "    x = np.asarray(x)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        n = len(x)\n",
    "        # Here, uppercase np.dtype.kind corresponds to non-numeric data.\n",
    "        # Also, we view the boolean data as dichotomous categorical data.\n",
    "        if x.dtype.kind.isupper() or x.dtype.kind == 'b':\n",
    "            cnt = pd.Series(x).value_counts(dropna=False)\n",
    "            card = len(cnt)\n",
    "            cnt = cnt[:20]\n",
    "            cnt_str = ', '.join([f'{u}:{c}' for u, c in zip(cnt.index, cnt)])\n",
    "            if card > 30:\n",
    "                cnt_str = f'{cnt_str}, ...'\n",
    "            return {\n",
    "                'n': n,\n",
    "                'cardinality': card,\n",
    "                'value_count': cnt_str\n",
    "            }\n",
    "        else:\n",
    "            x_nan = x[np.isnan(x)]\n",
    "            x_norm = x[~np.isnan(x)]\n",
    "            m = np.mean(x_norm)\n",
    "            me = np.median(x_norm)\n",
    "            s = np.std(x_norm, ddof=1)\n",
    "            l, u = np.min(x_norm), np.max(x)\n",
    "            conf_l, conf_u = st.t.interval(0.95, len(x_norm) - 1, loc=m, scale=st.sem(x_norm))\n",
    "            n_nan = len(x_nan)\n",
    "            return {\n",
    "                'n': n,\n",
    "                'mean': m,\n",
    "                'SD': s,\n",
    "                'med': me,\n",
    "                'range': (l, u),\n",
    "                'conf.': (conf_l, conf_u),\n",
    "                'nan_count': n_nan\n",
    "            }\n",
    "@contextmanager\n",
    "def on_ray(*args, **kwargs):\n",
    "    try:\n",
    "        if ray.is_initialized():\n",
    "            ray.shutdown()\n",
    "        ray.init(*args, **kwargs)\n",
    "        yield None\n",
    "    finally:\n",
    "        ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae36113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _safe_na_check(_v):\n",
    "    _is_nan_inf = False\n",
    "    try:\n",
    "        _is_nan_inf = np.isnan(_v) or np.isinf(_v)\n",
    "    except:\n",
    "        _is_nan_inf = False\n",
    "    return _is_nan_inf or _v is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c79667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_numeric_feature(d_key, d_val) -> Dict:\n",
    "    feature = {}\n",
    "    v=d_val\n",
    "    hist, _ = np.histogram(v, bins='doane', density=False)\n",
    "    std = np.sqrt(np.var(v, ddof=1)) if len(v) > 1 else 0\n",
    "    v_norm = (v - np.mean(v)) / std if std != 0 else np.zeros(len(v))\n",
    "    feature[f'{d_key}#AVG'] = np.mean(v) # Sample mean\n",
    "    feature[f'{d_key}#STD'] = std # Sample standard deviation\n",
    "    if std !=0:\n",
    "        feature[f'{d_key}#SKW'] = stats.skew(v, bias=False) # Sample skewness\n",
    "        feature[f'{d_key}#KUR'] = stats.kurtosis(v, bias=False) # Sample kurtosis\n",
    "    feature[f'{d_key}#ASC'] = np.sum(np.abs(np.diff(v))) # Abstract sum of changes\n",
    "    feature[f'{d_key}#BEP'] = stats.entropy(hist) # Binned entropy\n",
    "    feature[f'{d_key}#MED'] = np.median(v) # Median\n",
    "    feature[f'{d_key}#TSC'] = np.sqrt(np.sum(np.power(np.diff(v_norm), 2))) # Timeseries complexity\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c09af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_categorical_feature(cats, d_key, d_val) -> Dict:\n",
    "    feature = {}\n",
    "    v = d_val\n",
    "    cnt = v.value_counts()\n",
    "    val, sup = cnt.index, cnt.values\n",
    "    hist = {k: v for k, v in zip(val, sup)}\n",
    "    if len(cats) == 1:\n",
    "        c = cats[0]\n",
    "        feature[f'{d_key}#SUP'] = hist[c] if c in hist else 0\n",
    "    else:\n",
    "        # Information Entropy\n",
    "        feature[f'{d_key}#ETP#'] = stats.entropy(sup)\n",
    "        # Abs. Sum of Changes\n",
    "        feature[f'{d_key}#ASC#'] = np.sum(v.values[1:] != v.values[:-1])\n",
    "        if len(cats) == 2: # Dichotomous categorical data\n",
    "            c = cats[0]\n",
    "            feature[f'{d_key}#SUP'] = hist[c] if c in hist else 0\n",
    "        else:\n",
    "            for c in cats:\n",
    "                feature[f'{d_key}#SUP={c}'] = hist[c]  if c in hist else 0\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f7d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_timeWindow_feature(is_numeric, cats, d_key, d_val) -> Dict:\n",
    "    feature = {}\n",
    "    v = d_val\n",
    "    if d_key in ['CAE_DUR']:\n",
    "        feature = _extract_numeric_feature(d_key, v)\n",
    "        feature['CAE#FREQ'] = len(v)\n",
    "    elif d_key in ['MSG_SNT','MSG_RCV','MSG_ALL']:\n",
    "        feature[f'{d_key}#FREQ'] = np.sum(v) #As for ratio of inbound and outbound, we need to extract it after extracting for each sensor\n",
    "    elif d_key in ['LOC_CLS']:\n",
    "        feature = _extract_categorical_feature(cats, d_key, v)\n",
    "        feature['LOC#NumOfPlcVist'] = len(set(v))\n",
    "    else:\n",
    "        if is_numeric:\n",
    "            feature = _extract_numeric_feature(d_key, v)\n",
    "        else:\n",
    "            feature =_extract_categorical_feature(cats, d_key, v)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbf044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fucntion is based on the  towards circadian computing: \"early to bed and early to rise\"\n",
    "#makes some of us unhealthy and sleep derived\n",
    "theta=30\n",
    "def calculate_sleep_duration(s_on, s_off, theta):\n",
    "    # Merge s_on and s_off into a single DataFrame based on timestamp\n",
    "    df = pd.merge(pd.DataFrame({'timestamp': s_on, 'event': 'screen_on'}),\n",
    "                  pd.DataFrame({'timestamp': s_off, 'event': 'screen_off'}),\n",
    "                  how='outer', on='timestamp')\n",
    "    # fill missing values in event_x with values from event_y, and vice versa\n",
    "    df['event_x'] = df['event_x'].fillna(df['event_y'])\n",
    "    df['event_y'] = df['event_y'].fillna(df['event_x'])\n",
    "    # drop the event_x and event_y columns\n",
    "    df = df.drop(columns=['event_y']).rename(columns={'event_x': 'event'})\n",
    "    # Fill in missing timestamps with NaT and sort by timestamp\n",
    "    df = df.fillna(pd.NaT).sort_values('timestamp')\n",
    "    df=df.assign(\n",
    "         timestamp=lambda x: pd.to_datetime(x['timestamp'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "     )\n",
    "    # Filter out screen-on events caused by notifications\n",
    "    mask = (df['event'] == 'screen_off') & ((df['timestamp'].diff().fillna(pd.NaT)  / pd.Timedelta(seconds=1)) > theta)\n",
    "    filtered_df = df[mask].reset_index(drop=True)\n",
    "    # Discard non-usage patterns that do not start between 9PM to 7AM (next day)\n",
    "    sleep_duration = pd.Series(dtype=float)\n",
    "    sleep_onset = pd.Series(dtype=\"datetime64[ns]\")\n",
    "    for i in range(len(filtered_df)-1):\n",
    "        if filtered_df.loc[i, 'timestamp'].hour >= 21 or filtered_df.loc[i, 'timestamp'].hour < 7:\n",
    "            non_usage_duration = filtered_df.loc[i+1, 'timestamp'] - filtered_df.loc[i, 'timestamp']\n",
    "            if non_usage_duration.total_seconds() > 0:\n",
    "                sleep_duration = pd.concat([sleep_duration, pd.Series(non_usage_duration.total_seconds())])\n",
    "                sleep_onset = pd.concat([sleep_onset , pd.Series(filtered_df.loc[i, 'timestamp'])])\n",
    "    # Calculate sleep midpoint and apply individual corrective term\n",
    "    if len(sleep_duration) > 0:\n",
    "        sleep_duration = sleep_duration.reset_index(drop=True)\n",
    "        sleep_onset  =sleep_onset.reset_index(drop=True)\n",
    "        sleep_midpoint = sleep_onset + pd.to_timedelta(sleep_duration/2, unit=\"s\")\n",
    "        return sleep_duration.max(), sleep_onset.iloc[sleep_duration.idxmax()], sleep_midpoint.iloc[sleep_duration.idxmax()]\n",
    "    else:\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e44ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_names = {\n",
    "    0: 'Dawn',\n",
    "    1: 'Morning',\n",
    "    2: 'Afternoon',\n",
    "    3: 'LateAfternoon',\n",
    "    4: 'Evening',\n",
    "    5: 'Night'\n",
    "}\n",
    "def _extract(\n",
    "        pid: str,\n",
    "        data: Dict[str, pd.Series],\n",
    "        label: pd.Series,\n",
    "        label_values: List[str],\n",
    "#        window_data: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],\n",
    "#        window_label: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],\n",
    "        categories: Dict[str, Optional[List[any]]] = None,\n",
    "        constant_features: Dict[str, any] = None,\n",
    "        resample_s: Dict[str, float] = None\n",
    ") -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    _s = time.time()\n",
    "    log(f\"Begin feature extraction on {pid}'s data.\")\n",
    "    categories = categories or dict()\n",
    "    constant_features = constant_features or dict()\n",
    "    resample_s = resample_s or dict()\n",
    "    X, y, date_times = [], [], []\n",
    "#    count = 0\n",
    "    for timestamp in label.index:\n",
    "        row = dict()\n",
    "        #Find the start of today and yesterday for extracting today epoch features and yesterday epoch features\n",
    "        start_of_today = datetime(timestamp.year, timestamp.month, timestamp.day, tzinfo=timestamp.tzinfo)\n",
    "        start_of_today = pd.Timestamp(start_of_today.date(), tz=DEFAULT_TZ)\n",
    "        start_of_yesterday = timestamp - pd.Timedelta(days=1)\n",
    "        start_of_yesterday = pd.Timestamp(start_of_yesterday.date(), tz=DEFAULT_TZ)\n",
    "        label_cur = label.at[timestamp]\n",
    "        t = timestamp - td(milliseconds=1)\n",
    "        # Features relevant to participants' info\n",
    "        for d_key, d_val in constant_features.items():\n",
    "            row[d_key] = d_val\n",
    "        # Features from sensor data\n",
    "        for d_key, d_val in data.items():\n",
    "            is_numeric = d_key not in categories\n",
    "            cats = categories.get(d_key) or list()\n",
    "            d_val = d_val.sort_index()\n",
    "            # Features relevant to latest value of a given data\n",
    "            # These features are extracted only for bounded categorical data and numerical data.\n",
    "            if is_numeric or cats:\n",
    "                try:\n",
    "                    v = d_val.loc[:t].iloc[-1]\n",
    "                except (KeyError, IndexError):\n",
    "                    v = 0\n",
    "                if is_numeric:\n",
    "                    row[f'{d_key}#VAL'] = v\n",
    "                else:\n",
    "                    for c in cats:\n",
    "                        row[f'{d_key}#VAL={c}'] = v == c\n",
    "            # Features relevant to duration since the latest state change.\n",
    "            # These features are only for categorical data.\n",
    "            # In addition, duration since a given state is set recently is considered,\n",
    "            # that are available only at bounded categorical data.\n",
    "#             if not is_numeric:\n",
    "#                 try:\n",
    "#                     v = d_val.loc[:t]\n",
    "#                     row[f'{d_key}#DSC'] = (t - v.index[-1]).total_seconds() if len(v) else -1.0\n",
    "#                     for c in cats:\n",
    "#                         v_sub = v.loc[lambda x: x == c].index\n",
    "#                         row[f'{d_key}#DSC={c}'] = (t - v_sub[-1]).total_seconds() if len(v_sub) else -1.0\n",
    "#                 except (KeyError, IndexError):\n",
    "#                     row[f'{d_key}#DSC'] = -1.0\n",
    "#                     for c in cats:\n",
    "#                         row[f'{d_key}#DSC={c}'] = -1.0\n",
    "            # Features extracted from time-windows\n",
    "            # These features requires resampling and imputation on each data.\n",
    "            sample_rate = RESAMPLE_S.get(d_key) or 1\n",
    "            d_val_res = d_val.resample(f'{sample_rate}S', origin='start')\n",
    "            if d_val.dtypes != object:\n",
    "                d_val_res = d_val_res.mean().interpolate(method='linear').dropna()\n",
    "            else:\n",
    "                d_val_res = d_val_res.ffill().dropna()\n",
    "            #No resampling\n",
    "#             d_val_res =d_val\n",
    "           # Features extracted from immediate past time-windows\n",
    "            w_val = 15 * 60\n",
    "            v = d_val_res.loc[t - td(seconds=w_val):t]\n",
    "            if len(v) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                new_row = {f'{k}_ImmediatePast': v for k, v in _extract_timeWindow_feature(is_numeric, cats, d_key, v).items()}\n",
    "                row.update(new_row)\n",
    "            #Features extracted from yesterday epoch time windows\n",
    "            yesterday_time_windows = [\n",
    "                (start_of_yesterday + pd.Timedelta(hours=6), start_of_yesterday + pd.Timedelta(hours=9)),\n",
    "                (start_of_yesterday + pd.Timedelta(hours=9), start_of_yesterday + pd.Timedelta(hours=12)),\n",
    "                (start_of_yesterday + pd.Timedelta(hours=12), start_of_yesterday + pd.Timedelta(hours=15)),\n",
    "                (start_of_yesterday + pd.Timedelta(hours=15), start_of_yesterday + pd.Timedelta(hours=18)),\n",
    "                (start_of_yesterday + pd.Timedelta(hours=18), start_of_yesterday + pd.Timedelta(hours=21)),\n",
    "                (start_of_yesterday + pd.Timedelta(hours=21), start_of_yesterday + pd.Timedelta(hours=24))\n",
    "            ]\n",
    "            for count, (start, end) in enumerate(yesterday_time_windows):\n",
    "                # Get data for the current yesterday epoch time window\n",
    "                v = d_val_res.loc[start:end]\n",
    "                epoch_name = epoch_names.get(count)\n",
    "                if len(v) > 0:\n",
    "                    new_row = {f'{k}Yesterday{epoch_name}': v for k, v in _extract_timeWindow_feature(is_numeric, cats, d_key, v).items()}\n",
    "                    row.update(new_row)\n",
    "                    \n",
    "            #Features extracted from today epoch time windows until current time\n",
    "            today_time_windows = []\n",
    "            for i in range(6):\n",
    "                start = start_of_today + pd.Timedelta(hours=i*3)\n",
    "                end = start_of_today + pd.Timedelta(hours=(i+1)*3)\n",
    "                if start <= timestamp:\n",
    "                    today_time_windows.append((start, min(end, timestamp)))\n",
    "                else:\n",
    "                    break\n",
    "            for count, (start, end) in enumerate(today_time_windows):\n",
    "                # Get data for the current time window\n",
    "                v = d_val.loc[start:end]\n",
    "                epoch_name = epoch_names.get(count)\n",
    "                if len(v) > 0:\n",
    "                    new_row = {f'{k}Today{epoch_name}': v for k, v in _extract_timeWindow_feature(is_numeric, cats, d_key, v).items()}\n",
    "                    row.update(new_row)\n",
    "        #Sleep feature extracted from last night's data\n",
    "        onset_min = start_of_yesterday + pd.Timedelta(hours=21)\n",
    "        onset_max = start_of_today + pd.Timedelta(hours=14)\n",
    "        duration, onset, midpoint =calculate_sleep_duration(data['SCR_SON'].loc[onset_min:onset_max].reset_index()['timestamp'], data['SCR_DUR'].loc[onset_min:onset_max].reset_index()['timestamp'], theta)\n",
    "        if duration:\n",
    "            row['Sleep#Duration'] = duration\n",
    "            onset_hour = onset.hour\n",
    "            if onset_hour >=21:\n",
    "                row['Sleep#Onset'] = onset_hour - 21\n",
    "            else:\n",
    "                row['Sleep#Onset'] = onset_hour + 3\n",
    "\n",
    "        # Features relevant to time\n",
    "        day_of_week = ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN'][t.isoweekday() - 1]\n",
    "        is_weekend = 'Y' if t.isoweekday() > 5 else 'N'\n",
    "        hour = t.hour\n",
    "        if 6 <= hour < 9:\n",
    "            hour_name = 'DAWN'\n",
    "        elif 9 <= hour < 12:\n",
    "            hour_name = 'MORNING'\n",
    "        elif 12 <= hour < 15:\n",
    "            hour_name = 'AFTERNOON'\n",
    "        elif 15 <= hour < 18:\n",
    "            hour_name = 'LATE_AFTERNOON'\n",
    "        elif 18 <= hour < 21:\n",
    "            hour_name = 'EVENING'\n",
    "        elif 21 <= hour < 24:\n",
    "            hour_name = 'NIGHT'\n",
    "        else:\n",
    "            hour_name = 'MIDNIGHT'\n",
    "        for d in ['MON', 'TUE', 'WED', 'THU', 'FRI', 'SAT', 'SUN']:\n",
    "            row[f'Time#DOW={d}'] = d == day_of_week\n",
    "        for d in ['Y', 'N']:\n",
    "            row[f'Time#WKD={d}'] = d == is_weekend\n",
    "        for d in ['DAWN', 'MORNING', 'AFTERNOON', 'LATE_AFTERNOON', 'EVENING', 'NIGHT', 'MIDNIGHT']:\n",
    "            row[f'Time#HRN={d}'] = d == hour_name\n",
    "        try:\n",
    "            last_label = label.loc[label[:t].index.max()]['stress_dyn']\n",
    "        except (KeyError, IndexError):\n",
    "            last_label = -1\n",
    "        row[f'ESM#LastLabel'] = last_label\n",
    "        # Features extracted from previous respones behavior\n",
    "#         for w_key, w_val in window_label.items():\n",
    "#             w_val = w_val(t) if isinstance(w_val, Callable) else w_val\n",
    "#             try:\n",
    "#                 v = label.loc[t - td(seconds=w_val):t]\n",
    "#                 if len(label_values) <= 2: # Binary classification\n",
    "#                     row[f'ESM#LIK#{w_key}'] = np.sum(v == label_values[0]) / len(v) if len(v) > 0 else 0\n",
    "#                 else:\n",
    "#                     for l in label_values:\n",
    "#                         row[f'ESM#LIK={l}#{w_key}'] = np.sum(v == l) / len(v) if len(v) > 0 else 0\n",
    "#             except (KeyError, IndexError):\n",
    "#                 if len(label_values) <= 2:\n",
    "#                     row[f'ESM#LIK#{w_key}'] = 0\n",
    "#                 else:\n",
    "#                     for l in label_values:\n",
    "#                         row[f'ESM#LIK={l}#{w_key}'] = 0\n",
    "        row = {\n",
    "            k: 0.0 if _safe_na_check(v) else v\n",
    "            for k, v in row.items()\n",
    "        }\n",
    "\n",
    "        X.append(row)\n",
    "        y.append(label_cur)\n",
    "        date_times.append(timestamp)\n",
    "#         count = count +1\n",
    "#         if count>5:\n",
    "#             break\n",
    "\n",
    "    \n",
    "    log(f\"Complete feature extraction on {pid}'s data ({time.time() - _s:.2f} s).\")\n",
    "    X = pd.DataFrame(X)\n",
    "    y = np.asarray(y)\n",
    "    group = np.repeat(pid, len(y))\n",
    "    date_times =  np.asarray(date_times)\n",
    "    return X, y, group, date_times\n",
    "def extract(\n",
    "        pids: Iterable[str],\n",
    "        data: Dict[str, pd.Series],\n",
    "        label: pd.Series,\n",
    "        label_values: List[str],\n",
    "#        window_data: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],\n",
    "#        window_label: Dict[str, Union[int, Callable[[pd.Timestamp], int]]],\n",
    "        categories: Dict[str, Optional[List[any]]] = None,\n",
    "        constat_features: Dict[str, Dict[str, any]] = None,\n",
    "        resample_s: Dict[str, float] = None,\n",
    "        with_ray: bool=False\n",
    "):\n",
    "    if with_ray and not ray.is_initialized():\n",
    "        raise EnvironmentError('Ray should be initialized if \"with_ray\" is set as True.')\n",
    "    func = ray.remote(_extract).remote if with_ray else _extract\n",
    "    jobs = []\n",
    "    for pid in pids:\n",
    "        d = dict()\n",
    "        for k, v in data.items():\n",
    "            try:\n",
    "                d[k] = v.loc[(pid, )]\n",
    "                if k.startswith('LOC_'):\n",
    "                    d[k].index= pd.to_datetime( d[k].index, unit='ms', utc=True).tz_convert(DEFAULT_TZ)\n",
    "                d['SPEED'] = d.pop('LOC_SPEED')\n",
    "            except (KeyError, IndexError):\n",
    "                pass\n",
    "        job = func(\n",
    "            pid=pid, data=d, label=label.loc[(pid, )],\n",
    "            label_values=label_values,\n",
    "#            window_data=window_data,\n",
    "#            window_label=window_label,\n",
    "            categories=categories,\n",
    "            constant_features=constat_features[pid],\n",
    "            resample_s=resample_s\n",
    "        )\n",
    "        jobs.append(job)\n",
    "    jobs = ray.get(jobs) if with_ray else jobs\n",
    "    print([x.shape for _, x, _, _ in jobs])\n",
    "    X = pd.concat([x for x, _, _, _ in jobs], axis=0, ignore_index=True)\n",
    "    y = np.concatenate([x for _, x, _, _ in jobs], axis=0)\n",
    "    group = np.concatenate([x for _, _, x, _ in jobs], axis=0)\n",
    "    date_times = np.concatenate([x for _, _, _, x in jobs], axis=0)\n",
    "    t_s = date_times.min().normalize().timestamp()\n",
    "    t_norm = np.asarray(list(map(lambda x: x.timestamp() - t_s, date_times)))\n",
    "    C, DTYPE = X.columns, X.dtypes\n",
    "    X = X.fillna({\n",
    "        **{c: False for c in C[(DTYPE == object) | (DTYPE == bool)]},\n",
    "        **{c: 0.0 for c in C[(DTYPE != object) & (DTYPE != bool)]},\n",
    "    }).astype({\n",
    "        **{c: 'bool' for c in C[(DTYPE == object) | (DTYPE == bool)]},\n",
    "        **{c: 'float32' for c in C[(DTYPE != object) & (DTYPE != bool)]},\n",
    "    })\n",
    "    return X, y, group, t_norm, date_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17b1d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cloudpickle\n",
    "LABEL_VALUES = [1, 0]\n",
    "RESAMPLE_S = {\n",
    "    'ACC_AXX': 0.25,\n",
    "    'ACC_AXY': 0.25,\n",
    "    'ACC_AXZ': 0.25,\n",
    "    'ACC_MAG': 0.25,\n",
    "    'EDA': 0.5\n",
    "}\n",
    "CATEGORIES = {\n",
    "#    'DST_MOT': ['IDLE', 'WALKING', 'JOGGING', 'RUNNING'],\n",
    "#    'ULV_INT': ['NONE', 'LOW', 'MEDIUM', 'HIGH'],\n",
    "    'ACT_type': ['WALKING', 'STILL', 'IN_VEHICLE', 'ON_BICYCLE', 'RUNNING'],\n",
    "#    'APP_PAC': None,\n",
    "    'APP_CAT': ['SOCIAL','HEALTH','ENTER','WORK',\"INFO\"],\n",
    "#    'BAT_STA': ['CHARGING', 'DISCHARGING', 'FULL', 'NOT_CHARGING'],\n",
    "#    'CAE': ['CALL', 'IDLE'],\n",
    "#    'CON': ['DISCONNECTED', 'WIFI', 'MOBILE'],\n",
    "    'LOC_CLS': None,\n",
    "    'LOC_LABEL': ['eating','home','work','social','others'] ,\n",
    "    'SCR_SON': ['SON'],\n",
    "    'SCR_ULK': ['ULK']\n",
    "#     'RNG': ['VIBRATE', 'SILENT', 'NORMAL'],\n",
    "#     'CHG': ['DISCONNECTED', 'CONNECTED'],\n",
    "#     'PWS': ['ACTIVATE', 'DEACTIVATE'],\n",
    "#     'ONF': ['ON', 'OFF']\n",
    "}\n",
    "PARTICIPANTS = pd.read_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'PARTICIPANT_INFO.csv'),index_col = 'pcode')\n",
    "PINFO = PARTICIPANTS.assign(\n",
    "    age=lambda x: x['age'],\n",
    "    gender=lambda x: x['gender'],\n",
    "    openness=lambda x: x['openness'],\n",
    "    conscientiousness=lambda x: x['conscientiousness'],\n",
    "    neuroticism=lambda x: x['neuroticism'],\n",
    "    extraversion=lambda x: x['extraversion'],\n",
    "    agreeableness=lambda x: x['agreeableness'],\n",
    "    PSS10=lambda x: x['PSS10'],\n",
    "    GHQ12=lambda x: x['GHQ12'],\n",
    "    CESD_R=lambda x: x['CESD-R'],\n",
    "    self_efficacy=lambda x: x['self-efficacy'],\n",
    "    optimism=lambda x: x['optimism'],\n",
    "    hope=lambda x: x['hope'],\n",
    "    resiliency=lambda x: x['resiliency'],\n",
    ")[[\n",
    "    \"age\", \"gender\", \"openness\", \"conscientiousness\", \"neuroticism\", \"extraversion\", \"agreeableness\", \n",
    "    \"GHQ12\", \"PSS10\", \"CESD-R\", \"self-efficacy\", \"optimism\", \"hope\", \"resiliency\"\n",
    "]]\n",
    "\n",
    "PINFO = pd.get_dummies(PINFO, prefix_sep='=', dtype=bool).to_dict('index')\n",
    "PINFO = {k: {f'PIF#{x}': y for x, y in v.items()} for k, v in PINFO.items()}\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc', 'data_proc.pkl'))\n",
    "LABELS_PROC = pd.read_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'LABELS_PROC.csv'), index_col=['pcode','timestamp'],parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c216e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 19:42:01,145\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m [23-05-06 19:42:02] Begin feature extraction on P001's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116379)\u001b[0m [23-05-06 19:42:02] Begin feature extraction on P002's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m [23-05-06 19:42:02] Begin feature extraction on P003's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116374)\u001b[0m [23-05-06 19:42:02] Begin feature extraction on P007's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116376)\u001b[0m [23-05-06 19:42:03] Begin feature extraction on P008's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m [23-05-06 19:42:03] Begin feature extraction on P009's data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m [23-05-06 20:16:13] Complete feature extraction on P001's data (2050.94 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m [23-05-06 20:16:13] Begin feature extraction on P010's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116374)\u001b[0m [23-05-06 20:19:11] Complete feature extraction on P007's data (2228.81 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=116374)\u001b[0m [23-05-06 20:19:11] Begin feature extraction on P011's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m [23-05-06 20:25:47] Complete feature extraction on P003's data (2625.14 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=116378)\u001b[0m [23-05-06 20:25:48] Begin feature extraction on P013's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116379)\u001b[0m [23-05-06 20:27:04] Complete feature extraction on P002's data (2701.80 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=116379)\u001b[0m [23-05-06 20:27:04] Begin feature extraction on P014's data.\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m [23-05-06 20:35:01] Complete feature extraction on P009's data (3178.53 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=116377)\u001b[0m [23-05-06 20:35:02] Begin feature extraction on P015's data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116374)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116374)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116376)\u001b[0m [23-05-06 20:40:37] Complete feature extraction on P008's data (3513.96 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=116376)\u001b[0m [23-05-06 20:40:37] Begin feature extraction on P016's data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m [23-05-06 20:51:50] Complete feature extraction on P010's data (2137.19 s).\n",
      "\u001b[2m\u001b[36m(_extract pid=116375)\u001b[0m [23-05-06 20:51:51] Begin feature extraction on P018's data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116379)\u001b[0m /tmp/ipykernel_116038/22028349.py:10: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "\u001b[2m\u001b[36m(_extract pid=116379)\u001b[0m /tmp/ipykernel_116038/22028349.py:11: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_extract pid=116379)\u001b[0m [23-05-06 21:00:35] Complete feature extraction on P014's data (2011.20 s).\n"
     ]
    },
    {
     "ename": "RayTaskError(ValueError)",
     "evalue": "\u001b[36mray::_extract()\u001b[39m (pid=116379, ip=192.168.1.27)\n  File \"/tmp/ipykernel_116038/3290932600.py\", line 194, in _extract\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (182,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m         labels \u001b[38;5;241m=\u001b[39m LABELS_PROC[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_dyn\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m         pids \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcode\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m---> 14\u001b[0m         feat \u001b[38;5;241m=\u001b[39m \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLABEL_VALUES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;43;03m#            window_data=WINDOW_DATA,\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;43;03m#            window_label=WINDOW_LABEL,\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcategories\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCATEGORIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconstat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPINFO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresample_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRESAMPLE_S\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_ray\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m         dump(feat, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_INTERMEDIATE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeat\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[7], line 234\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(pids, data, label, label_values, categories, constat_features, resample_s, with_ray)\u001b[0m\n\u001b[1;32m    224\u001b[0m     job \u001b[38;5;241m=\u001b[39m func(\n\u001b[1;32m    225\u001b[0m         pid\u001b[38;5;241m=\u001b[39mpid, data\u001b[38;5;241m=\u001b[39md, label\u001b[38;5;241m=\u001b[39mlabel\u001b[38;5;241m.\u001b[39mloc[(pid, )],\n\u001b[1;32m    226\u001b[0m         label_values\u001b[38;5;241m=\u001b[39mlabel_values,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m         resample_s\u001b[38;5;241m=\u001b[39mresample_s\n\u001b[1;32m    232\u001b[0m     )\n\u001b[1;32m    233\u001b[0m     jobs\u001b[38;5;241m.\u001b[39mappend(job)\n\u001b[0;32m--> 234\u001b[0m jobs \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m with_ray \u001b[38;5;28;01melse\u001b[39;00m jobs\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mprint\u001b[39m([x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m _, x, _, _ \u001b[38;5;129;01min\u001b[39;00m jobs])\n\u001b[1;32m    236\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([x \u001b[38;5;28;01mfor\u001b[39;00m x, _, _, _ \u001b[38;5;129;01min\u001b[39;00m jobs], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/sci-data/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sci-data/lib/python3.9/site-packages/ray/_private/worker.py:2309\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2307\u001b[0m     worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[1;32m   2308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m-> 2309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   2310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2311\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mRayTaskError(ValueError)\u001b[0m: \u001b[36mray::_extract()\u001b[39m (pid=116379, ip=192.168.1.27)\n  File \"/tmp/ipykernel_116038/3290932600.py\", line 194, in _extract\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (182,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "with on_ray(num_cpus=6):\n",
    "    #for l in ['valence', 'arousal', 'stress', 'disturbance']:\n",
    "    for l in ['stress']:\n",
    "        #In preprocessing, dynamic threshold shows better data balance\n",
    "        labels = LABELS_PROC[f'{l}_dyn']\n",
    "        pids = labels.index.get_level_values('pcode').unique()\n",
    "        feat = extract(\n",
    "            pids=pids,\n",
    "            data=DATA,\n",
    "            label=labels,\n",
    "            label_values=LABEL_VALUES,\n",
    "#            window_data=WINDOW_DATA,\n",
    "#            window_label=WINDOW_LABEL,\n",
    "            categories=CATEGORIES,\n",
    "            constat_features=PINFO,\n",
    "            resample_s=RESAMPLE_S,\n",
    "            with_ray=True\n",
    "        )\n",
    "        dump(feat, os.path.join(PATH_INTERMEDIATE, 'feat', f'{l}.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
